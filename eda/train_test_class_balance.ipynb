{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eacf354-5bcd-4fd3-b13e-881b4b1ccb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ====== Custom Dataset ======\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if not self.transform is None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "def to_rgb(image):\n",
    "    return image.convert('RGB') if image.mode != 'RGB' else image\n",
    "\n",
    "dataset = torch.load(\"Train.pt\", weights_only=False)\n",
    "dataset = [(idx, to_rgb(img), label) for idx, img, label in data]\n",
    "labels = [label for _, _, label in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d72d96ed-7de1-4e23-8591-95a8ab108dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Stratified Split with Rare Tag Handling ======\n",
    "labels_np = np.array(labels)\n",
    "tag_counts = Counter(labels_np)\n",
    "rare_indices = np.array([i for i, tag in enumerate(labels_np) if tag_counts[tag] < 2])\n",
    "strat_eligible = np.array([i for i, tag in enumerate(labels_np) if tag_counts[tag] >= 2])\n",
    "strat_tags = labels_np[strat_eligible]\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx_r, test_idx_r = next(sss.split(strat_eligible, strat_tags))\n",
    "\n",
    "train_idx_r = strat_eligible[train_idx_r]\n",
    "test_idx_r = strat_eligible[test_idx_r]\n",
    "train_idx = np.concatenate([rare_indices, train_idx_r])\n",
    "test_idx = test_idx_r\n",
    "\n",
    "train_data = Subset(dataset, train_idx)\n",
    "test_data = Subset(dataset, test_idx)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c19baa1-c4b6-4027-9761-04be6b9d747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def check_distribution_across_splits(train_idx, test_idx, data):\n",
    "    # Extract labels for all data points by idx\n",
    "    labels = {idx: label for idx, _, label in data}\n",
    "    \n",
    "    tag_counts = defaultdict(lambda: {\"train\": 0, \"test\": 0, \"total\": 0})\n",
    "\n",
    "    for idx in train_idx:\n",
    "        tag = labels.get(idx)\n",
    "        if tag is not None:\n",
    "            tag_counts[tag][\"train\"] += 1\n",
    "            tag_counts[tag][\"total\"] += 1\n",
    "\n",
    "    for idx in test_idx:\n",
    "        tag = labels.get(idx)\n",
    "        if tag is not None:\n",
    "            tag_counts[tag][\"test\"] += 1\n",
    "            tag_counts[tag][\"total\"] += 1\n",
    "\n",
    "    # Print header\n",
    "    print(f\"{'Tag':<15} {'Train':>7} {'Test':>7} {'Total':>7} | {'Train %':>8} {'Test %':>8}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    for tag in sorted(tag_counts.keys()):\n",
    "        info = tag_counts[tag]\n",
    "        total = info[\"total\"]\n",
    "        train_pct = 100 * info[\"train\"] / total if total else 0\n",
    "        test_pct = 100 * info[\"test\"] / total if total else 0\n",
    "        print(f\"{tag:<15} {info['train']:>7}  {info['test']:>7} {total:>7} | {train_pct:7.2f}%  {test_pct:7.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a124d6b4-17bd-4fa7-95ec-7b6872920c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag               Train    Test   Total |  Train %   Test %\n",
      "----------------------------------------------------------------------\n",
      "0                   338       86     424 |   79.72%    20.28%\n",
      "1                  6650     1682    8332 |   79.81%    20.19%\n",
      "2                 17005     4214   21219 |   80.14%    19.86%\n",
      "3                  2613      648    3261 |   80.13%    19.87%\n",
      "4                  5105     1310    6415 |   79.58%    20.42%\n",
      "5                 10829     2697   13526 |   80.06%    19.94%\n",
      "6                  3380      861    4241 |   79.70%    20.30%\n",
      "7                   329       80     409 |   80.44%    19.56%\n",
      "8                 22994     5795   28789 |   79.87%    20.13%\n",
      "9                  3414      854    4268 |   79.99%    20.01%\n"
     ]
    }
   ],
   "source": [
    "check_distribution_across_splits(train_idx, test_idx, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
